{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proejct 2.ipynb",
      "provenance": [],
      "mount_file_id": "1LTNRmvD13IDwcS2Pt1gqRfC0YEPMvi1Z",
      "authorship_tag": "ABX9TyPLiWG22isd7oWlzNblifGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinayak15/NLP-Project-2/blob/main/Proejct_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIIrfo-wqaPE",
        "outputId": "dbdb3c3a-2c50-4e60-b36c-2b23e5e00230"
      },
      "source": [
        "%cd /content/drive/MyDrive/NLP/Project2/joint_model/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/Project2/joint_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUrqNkzdrywT"
      },
      "source": [
        "!git clone https://github.com/luomancs/joint_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujk9yAhj1OGr"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toE5l7PTD2o6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc917070-fcaf-4904-b9f2-6db3b2325c84"
      },
      "source": [
        "!pip uninstall apex"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: apex 0.9.10.dev0\n",
            "Uninstalling apex-0.9.10.dev0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/apex-0.9.10.dev0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/apex/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled apex-0.9.10.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyKEEKLVLkOu"
      },
      "source": [
        "import json, os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import string \n",
        "import math\n",
        "\n",
        "from common.utils_plus import *\n",
        "\n",
        "def hotpot(read_path, save_path,mode=\"train\"):\n",
        "    posi_para = []\n",
        "    neg_para = []\n",
        "    data = json_plus.load(read_path)\n",
        "    for i,item in enumerate(tqdm(data)):\n",
        "        question = item['question'] \n",
        "        answer = item['answer']\n",
        "        supporting_title = {}\n",
        "        for sp in item['supporting_facts']:\n",
        "            title = sp[0]\n",
        "            idx = sp[1]\n",
        "            if title not in supporting_title:\n",
        "                supporting_title[title] = [idx]\n",
        "            else:\n",
        "                supporting_title[title].append(idx)\n",
        "        \n",
        "        for para in item['context']:\n",
        "            title = para[0]\n",
        "            sents_label = [-1]*(len(para[1]))\n",
        "            para_label = -1\n",
        "            if  title in supporting_title:\n",
        "                para_label = 1\n",
        "                for idx in supporting_title[title]:\n",
        "                    if  idx < len(para[1]):\n",
        "                        sents_label[idx] = 1\n",
        "            \n",
        "            datum = {\n",
        "                'para':\"</s> \".join([question]+para[1][:9]),\n",
        "                'para_label':para_label,\n",
        "                'sents_label':sents_label[:9],\n",
        "                'answer_label': answer\n",
        "            }\n",
        "            if title in supporting_title:\n",
        "                posi_para.append(datum)\n",
        "            else:\n",
        "                neg_para.append(datum)\n",
        "              \n",
        "\n",
        "    if mode==\"train\":\n",
        "        neg_para = random.sample(neg_para, len(posi_para))\n",
        "    all_samples = posi_para+neg_para\n",
        "    print(all_samples)\n",
        "    print(len(all_samples))\n",
        "    jsonline_plus.dump(all_samples, save_path)\n",
        "\n",
        "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "\n",
        "def normalize(str1):\n",
        "    str2 = str1.translate(translator)\n",
        "    str2 = str2.lower().replace(\" \",\"\")\n",
        "    return str2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJNUHNdIL4IK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f5e36c-ccf9-4b30-d00b-fac3fa2da52f"
      },
      "source": [
        "hotpot('/content/drive/MyDrive/NLP/Project2/dev.json', '/content/drive/MyDrive/NLP/Project2/joint_model/dataset/para_training/dev.jsonl',mode=\"dev\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7405/7405 [00:00<00:00, 19358.71it/s]\n",
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reXqDyR8B4v8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdaaec2-f8c9-4777-ba2d-d40271f14ad2"
      },
      "source": [
        "!python model_train/train_para.py \\\n",
        "--model_name_or_path roberta-base \\\n",
        "--tokenizer_name roberta-base \\\n",
        "--task_name para \\\n",
        "--data_dir dataset/para_training/ \\\n",
        "--max_seq_length 512 \\\n",
        "--output_dir path_to_save_model \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--overwrite_output_dir \\\n",
        "--per_device_train_batch_size 4 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "--per_device_eval_batch_size 32 \\\n",
        "--learning_rate 1e-5 \\\n",
        "--num_train_epochs 5 \\\n",
        "--save_steps 10000 \\\n",
        "--logging_steps 10000 \\\n",
        "--use_sent_loss \\"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/27/2021 05:07:09 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "11/27/2021 05:07:09 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=0,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=2,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=path_to_save_model/runs/Nov27_05-07-09_ecc1aa170d9b,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10000,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5.0,\n",
            "output_dir=path_to_save_model,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=32,\n",
            "per_device_train_batch_size=4,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=path_to_save_model,\n",
            "save_on_each_node=False,\n",
            "save_steps=10000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "use sentence loss in the training:  True\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "11/27/2021 05:07:23 - INFO - glue_dataset -   Creating features from dataset file at dataset/para_training/\n",
            "Generating: 361788it [00:02, 126965.05it/s]\n",
            "InputExample(guid='train-0', text_a='Which magazine was started first Arthur\\'s Magazine or First for Women?</s> Arthur\\'s Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century.</s>  Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others.</s>  In May 1846 it was merged into \"Godey\\'s Lady\\'s Book\".', text_b='', label=([1, 1, -1, -1, 0, 0, 0, 0, 0, 0], \"Arthur's Magazine\"))\n",
            "Traceback (most recent call last):\n",
            "  File \"model_train/train_para.py\", line 274, in <module>\n",
            "    main()\n",
            "  File \"model_train/train_para.py\", line 167, in main\n",
            "    GlueDataset(data_args, tokenizer=tokenizer, cache_dir=model_args.cache_dir,data_lim=model_args.data_lim) if training_args.do_train else None\n",
            "  File \"/content/drive/My Drive/NLP/Project2/joint_model/model_train/glue_dataset.py\", line 128, in __init__\n",
            "    output_mode=self.output_mode,\n",
            "  File \"/content/drive/My Drive/NLP/Project2/joint_model/model_train/utils.py\", line 124, in glue_convert_examples_to_features\n",
            "    examples, tokenizer, max_length=max_length, task=task, label_list=label_list, output_mode=output_mode\n",
            "  File \"/content/drive/My Drive/NLP/Project2/joint_model/model_train/utils.py\", line 294, in _glue_convert_examples_to_features\n",
            "    inputs = {k: tokenized_examples[k][i] for k in tokenized_examples}\n",
            "  File \"/content/drive/My Drive/NLP/Project2/joint_model/model_train/utils.py\", line 294, in <dictcomp>\n",
            "    inputs = {k: tokenized_examples[k][i] for k in tokenized_examples}\n",
            "IndexError: list index out of range\n"
          ]
        }
      ]
    }
  ]
}